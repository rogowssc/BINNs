{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d24c4ff-61c9-4875-8ec0-1ba84a222fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covasim 3.1.3 (2022-07-19) — © 2020-2022 by IDM\n",
      "Device set to cpu\n",
      "Epoch 64563 | Train loss = 6.2757e-02 | Val loss = 2.3621e-02 | Elapsed = 2:03:59                 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from Modules.Utils.Imports import *\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "from Modules.Models.BuildBINNs import BINNCovasim\n",
    "\n",
    "import Modules.Loaders.DataFormatter as DF\n",
    "import datetime\n",
    "\n",
    "from utils import plot_loss_convergence, get_case_name\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "device = torch.device(GetLowestGPU(pick_from=[0,1,2,3]))\n",
    "# torch.manual_seed(9099058152467048838)\n",
    "# np.random.seed(1232914967)\n",
    "\n",
    "path = '../Data/covasim_data/'\n",
    "population = 200000\n",
    "test_prob = 0.1\n",
    "trace_prob = 0.3\n",
    "keep_d = True\n",
    "retrain = False\n",
    "dynamic=True\n",
    "chi_type = 'piecewise'\n",
    "case_name = get_case_name(population, test_prob, trace_prob, keep_d, dynamic=dynamic, chi_type=chi_type)\n",
    "# yita_lb, yita_ub = 0.2, 0.4\n",
    "\n",
    "params = DF.load_covasim_data(path, population, test_prob, trace_prob, case_name,plot=True)\n",
    "\n",
    "def to_torch(ndarray):\n",
    "    arr = torch.tensor(ndarray, dtype=torch.float)\n",
    "    arr.requires_grad_(True)\n",
    "    arr = arr.to(device)\n",
    "    return arr\n",
    "\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()\n",
    "\n",
    "# split into train/val and convert to torch\n",
    "data = params['data']\n",
    "data = (data / params['population']).to_numpy()\n",
    "params.pop('data')\n",
    "N = len(data)\n",
    "split = int(0.8*N)\n",
    "p = np.random.permutation(N)\n",
    "x_train = to_torch(p[:split][:, None]/(N-1))\n",
    "y_train = to_torch(data[p[:split]])\n",
    "x_val = to_torch(p[split:][:, None]/(N-1))\n",
    "y_val = to_torch(data[p[split:]])\n",
    "\n",
    "# generate save path\n",
    "mydir = os.path.join('../models/covasim', datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "os.makedirs(mydir)\n",
    "\n",
    "tracing_array = params['tracing_array']\n",
    "# initialize model\n",
    "binn = BINNCovasim(params, N - 1, tracing_array, keep_d=keep_d, chi_type=chi_type)\n",
    "binn.to(device)\n",
    "\n",
    "# compile\n",
    "parameters = binn.parameters()\n",
    "opt = torch.optim.Adam(parameters, lr=1e-3)\n",
    "os.makedirs(os.path.join(mydir, case_name))\n",
    "model = ModelWrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    # scheduler= scheduler,\n",
    "    save_name=os.path.join(mydir, case_name) )\n",
    "model.str_name = 'STEAYDQRF'\n",
    "\n",
    "# save the range information before training\n",
    "ranges = [binn.yita_lb, binn.yita_ub, binn.beta_lb, binn.beta_ub, binn.tau_lb, binn.tau_ub]\n",
    "file_name = '_'.join([str(m) for m in ranges])\n",
    "joblib.dump(None, os.path.join(mydir, file_name)) # model.save_folder\n",
    "# if retrain\n",
    "if retrain:\n",
    "    model.load(model.save_name + '_best_val_model', device=device)\n",
    "    model.model.train()\n",
    "    model.save_name += '_retrain'\n",
    "epochs = int(10e4)\n",
    "batch_size = 128\n",
    "rel_save_thresh = 0.05\n",
    "\n",
    "# train jointly\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=None,\n",
    "    verbose=1,\n",
    "    validation_data=[x_val, y_val],\n",
    "    early_stopping=40000,\n",
    "    rel_save_thresh=rel_save_thresh)\n",
    "\n",
    "\n",
    "# # fitting performance on training data\n",
    "# y_train_pred = to_numpy(model.predict(x_train))\n",
    "\n",
    "\n",
    "# load training errors\n",
    "total_train_losses = model.train_loss_list\n",
    "total_val_losses = model.val_loss_list\n",
    "\n",
    "plot_loss_convergence(total_train_losses, total_val_losses, rel_save_thresh, model.save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaebb7d-1141-4ba7-a11a-a3976cf1bf17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
